{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dskU5JtDOcUZ"
      },
      "outputs": [],
      "source": [
        "!pip install mlflow -q\n",
        "!pip install pyngrok -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mINo_z7pPh2H"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import subprocess\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "from hyperopt.pyll import scope\n",
        "\n",
        "from mlflow import MlflowClient\n",
        "from mlflow.entities import ViewType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AODTjOYy4FMG"
      },
      "source": [
        "**Que 1**. Mlflow version?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AClOz0zfl2Tj",
        "outputId": "8c54a18a-9edc-4be4-b580-5d2f7c807a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mlflow, version 2.22.0\n"
          ]
        }
      ],
      "source": [
        "!mlflow --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2rNfxYkYvM9k"
      },
      "outputs": [],
      "source": [
        "def preprocess_data():\n",
        "\n",
        "    def dump_pickle(obj, filename: str):\n",
        "        with open(filename, \"wb\") as f_out:\n",
        "            return pickle.dump(obj, f_out)\n",
        "\n",
        "    def read_dataframe(filename: str):\n",
        "        df = pd.read_parquet(filename)\n",
        "\n",
        "        df['duration'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
        "        df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
        "        df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
        "\n",
        "        categorical = ['PULocationID', 'DOLocationID']\n",
        "        df[categorical] = df[categorical].astype(str)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
        "\n",
        "        df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
        "        categorical = ['PU_DO']\n",
        "        numerical = ['trip_distance']\n",
        "        dicts = df[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "        if fit_dv: X = dv.fit_transform(dicts)\n",
        "        else: X = dv.transform(dicts)\n",
        "        return X, dv\n",
        "\n",
        "    def run_data_prep(raw_data_path='/content', dest_path='/content/Output', dataset: str = \"green\"):\n",
        "\n",
        "        df_train = read_dataframe(os.path.join(raw_data_path, f\"{dataset}_tripdata_2023-01.parquet\"))\n",
        "        df_val = read_dataframe(os.path.join(raw_data_path, f\"{dataset}_tripdata_2023-02.parquet\"))\n",
        "        df_test = read_dataframe(os.path.join(raw_data_path, f\"{dataset}_tripdata_2023-03.parquet\"))\n",
        "\n",
        "        target = 'duration'\n",
        "        y_train = df_train[target].values\n",
        "        y_val = df_val[target].values\n",
        "        y_test = df_test[target].values\n",
        "\n",
        "        dv = DictVectorizer()\n",
        "        X_train, dv = preprocess(df_train, dv, fit_dv=True)\n",
        "        X_val, _ = preprocess(df_val, dv, fit_dv=False)\n",
        "        X_test, _ = preprocess(df_test, dv, fit_dv=False)\n",
        "\n",
        "        os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "        dump_pickle(dv, os.path.join(dest_path, \"dv.pkl\"))\n",
        "        dump_pickle((X_train, y_train), os.path.join(dest_path, \"train.pkl\"))\n",
        "        dump_pickle((X_val, y_val), os.path.join(dest_path, \"val.pkl\"))\n",
        "        dump_pickle((X_test, y_test), os.path.join(dest_path, \"test.pkl\"))\n",
        "\n",
        "    run_data_prep()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l_qiSBjuy1bU"
      },
      "outputs": [],
      "source": [
        "preprocess_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVv2RrUr4Lm6"
      },
      "source": [
        "**Que 2**. Number of files that were saved in output folder?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEAqPN794UrX",
        "outputId": "1afc1ee7-2193-44c3-ce6e-2e6085213af0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in output folder: 4\n"
          ]
        }
      ],
      "source": [
        "print('Number of files in output folder: ', end='')\n",
        "!ls /content/Output | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YSBDbvjMv01k"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "\n",
        "    def load_pickle(filename: str):\n",
        "        with open(filename, \"rb\") as f_in:\n",
        "            return pickle.load(f_in)\n",
        "\n",
        "    def run_train(data_path='/content/Output'):\n",
        "\n",
        "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
        "        X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
        "\n",
        "        mlflow.autolog()\n",
        "\n",
        "        with mlflow.start_run():\n",
        "            rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
        "            rf.fit(X_train, y_train)\n",
        "            y_pred = rf.predict(X_val)\n",
        "\n",
        "        rmse = root_mean_squared_error(y_val, y_pred)\n",
        "\n",
        "    run_train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hW3cEFwyy5vG",
        "outputId": "4cd7ac65-a297-400e-951b-537954e99a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/26 15:22:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2025/05/26 15:22:30 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
            "2025/05/26 15:22:30 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2025/05/26 15:22:30 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
          ]
        }
      ],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF5tMd6I6j5P"
      },
      "source": [
        "**Que 3**. Value of min_sample_slit?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lLCmE8ZZFu8J"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/mlruns/0/45a4e765f3984c77a2bbdd5aa05a2d18/params/min_samples_split'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZzLXR0EF-CH",
        "outputId": "a3d8cd59-5510-488c-ec1b-e8101531b840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_sample_split: 2\n"
          ]
        }
      ],
      "source": [
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "    print(f'min_sample_split: {content}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Que 4.** What else do you need to configure server?"
      ],
      "metadata": {
        "id": "W1Lp21JLN3OL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQE2JhHWAHC3"
      },
      "outputs": [],
      "source": [
        "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
        "FOLDER = '/content/artifacts'\n",
        "\n",
        "subprocess.Popen([\"mlflow\", \"server\", \"--backend-store-uri\", MLFLOW_TRACKING_URI, '--default-artifact-root', FOLDER, \"--port\", \"5000\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need defalut artifact root as well to configure server."
      ],
      "metadata": {
        "id": "pyVeRZ3GN63T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9fiF1DLkHF4i"
      },
      "outputs": [],
      "source": [
        "conf.get_default().auth_token = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXz5QoTiA-rV",
        "outputId": "bcb6671b-4d0c-4eae-f6af-771063ee138a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://6e10-34-82-19-184.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n"
          ]
        }
      ],
      "source": [
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f' * ngrok tunnel \"{public_url}\" -> \"http://127.0.0.1:{port}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6_kBTNTI3FDy"
      },
      "outputs": [],
      "source": [
        "def hpo():\n",
        "\n",
        "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
        "    mlflow.set_experiment(\"random-forest-hyperopt\")\n",
        "\n",
        "    def load_pickle(filename: str):\n",
        "        with open(filename, \"rb\") as f_in:\n",
        "            return pickle.load(f_in)\n",
        "\n",
        "    def run_optimization(data_path='/content/Output', num_trials=15):\n",
        "\n",
        "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
        "        X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
        "\n",
        "        def objective(params):\n",
        "\n",
        "            with mlflow.start_run():\n",
        "\n",
        "                mlflow.log_params(params)\n",
        "\n",
        "                rf = RandomForestRegressor(**params)\n",
        "                rf.fit(X_train, y_train)\n",
        "                y_pred = rf.predict(X_val)\n",
        "                rmse = root_mean_squared_error(y_val, y_pred)\n",
        "\n",
        "                mlflow.log_metric('RMSE', rmse)\n",
        "\n",
        "                return {'loss': rmse, 'status': STATUS_OK}\n",
        "\n",
        "        search_space = {\n",
        "            'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
        "            'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
        "            'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "            'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        rstate = np.random.default_rng(42)\n",
        "        fmin(\n",
        "            fn=objective,\n",
        "            space=search_space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=num_trials,\n",
        "            trials=Trials(),\n",
        "            rstate=rstate\n",
        "        )\n",
        "\n",
        "    run_optimization()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VptD3PHt3PZf"
      },
      "outputs": [],
      "source": [
        "hpo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikzuoRCjKQ49"
      },
      "source": [
        "**Que 5.** Minimum validation RMSE value?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = MlflowClient()"
      ],
      "metadata": {
        "id": "MtmVg7IPM8X-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYArI6h6HiYc",
        "outputId": "c40bcc4f-7cf0-4901-d292-9b8d065134b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum_validation_rmse: 5.335419588556921\n"
          ]
        }
      ],
      "source": [
        "runs = client.search_runs(experiment_ids=[client.get_experiment_by_name('random-forest-hyperopt').experiment_id])\n",
        "valid_rmse = sorted([run.data.metrics['RMSE'] for run in runs])\n",
        "print(f'minimum_validation_rmse: {valid_rmse[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9NlDnziHKHVF"
      },
      "outputs": [],
      "source": [
        "def register_model():\n",
        "    HPO_EXPERIMENT_NAME = \"random-forest-hyperopt\"\n",
        "    EXPERIMENT_NAME = \"random-forest-best-models\"\n",
        "    RF_PARAMS = ['max_depth', 'n_estimators', 'min_samples_split', 'min_samples_leaf', 'random_state']\n",
        "\n",
        "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "\n",
        "    def load_pickle(filename):\n",
        "        with open(filename, \"rb\") as f_in:\n",
        "            return pickle.load(f_in)\n",
        "\n",
        "\n",
        "    def train_and_log_model(data_path, params):\n",
        "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
        "        X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
        "        X_test, y_test = load_pickle(os.path.join(data_path, \"test.pkl\"))\n",
        "\n",
        "        with mlflow.start_run():\n",
        "            new_params = {}\n",
        "            for param in RF_PARAMS:\n",
        "                new_params[param] = int(params[param])\n",
        "\n",
        "            rf = RandomForestRegressor(**new_params)\n",
        "            rf.fit(X_train, y_train)\n",
        "\n",
        "            # Evaluate model on the validation and test sets\n",
        "            val_rmse = root_mean_squared_error(y_val, rf.predict(X_val))\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            test_rmse = root_mean_squared_error(y_test, rf.predict(X_test))\n",
        "            mlflow.log_metric(\"test_rmse\", test_rmse)\n",
        "\n",
        "    def run_register_model(data_path='/content/Output', top_n=5):\n",
        "\n",
        "        client = MlflowClient()\n",
        "\n",
        "        # Retrieve the top_n model runs and log the models\n",
        "        experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
        "        runs = client.search_runs(\n",
        "            experiment_ids=experiment.experiment_id,\n",
        "            run_view_type=ViewType.ACTIVE_ONLY,\n",
        "            max_results=top_n,\n",
        "            order_by=[\"metrics.rmse ASC\"]\n",
        "        )\n",
        "        for run in runs:\n",
        "            train_and_log_model(data_path=data_path, params=run.data.params)\n",
        "\n",
        "        # Select the model with the lowest test RMSE\n",
        "        experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
        "        best_run = client.search_runs(\n",
        "            experiment_ids=experiment.experiment_id,\n",
        "            order_by=['metrics.test_rmse ASC']\n",
        "        )[0]\n",
        "\n",
        "        # Register the best model\n",
        "        mlflow.register_model(\n",
        "            model_uri=f'runs:/{best_run.info.run_id}/model',\n",
        "            name='random-forest-model-registry'\n",
        "        )\n",
        "\n",
        "    run_register_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iJXIXkOWQC7",
        "outputId": "7ab15e1c-851b-4429-c974-36c495b8d4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/26 15:31:59 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-best-models' does not exist. Creating a new experiment.\n",
            "Successfully registered model 'random-forest-model-registry'.\n",
            "Created version '1' of model 'random-forest-model-registry'.\n"
          ]
        }
      ],
      "source": [
        "register_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v_b9G_CZ1iG"
      },
      "source": [
        "**Que 6.** Test_rmse for registered model?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK7CJ4EpWSC9",
        "outputId": "7d70f3c0-89b6-4a19-f437-3a91bb132ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_rmse: 5.567408012462019\n"
          ]
        }
      ],
      "source": [
        "model = client.get_registered_model('random-forest-model-registry')\n",
        "run_id = model.latest_versions[0].run_id\n",
        "test_rmse = client.get_run(run_id).data.metrics['test_rmse']\n",
        "print(f'test_rmse: {test_rmse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKsazvqfZyf_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nXk-FTutOvZh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy7rJzrYFWF0GLPDWzfYiO"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}