{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dskU5JtDOcUZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install mlflow -q\n",
        "!pip install pyngrok -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mINo_z7pPh2H"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import subprocess\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqxX5aW-NqVu"
      },
      "outputs": [],
      "source": [
        "# Define the MLflow tracking URI with SQLite\n",
        "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
        "\n",
        "# Start the MLflow server using subprocess\n",
        "subprocess.Popen([\"mlflow\", \"ui\", \"--backend-store-uri\", MLFLOW_TRACKING_URI, \"--port\", \"5000\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PSY9uY40ObMf"
      },
      "outputs": [],
      "source": [
        "# Set MLflow tracking URI\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gY3yqDzPqg3",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Set up ngrok for exposing the MLflow UI\n",
        "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/auth\")\n",
        "conf.get_default().auth_token = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pppwHCGiQVwp",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Expose the MLflow UI on port 5000\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f' * ngrok tunnel \"{public_url}\" -> \"http://127.0.0.1:{port}\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "\n",
        "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
        "from hyperopt.pyll import scope\n",
        "\n",
        "from mlflow import MlflowClient\n",
        "from mlflow.entities import ViewType"
      ],
      "metadata": {
        "id": "ABzPoejme98l"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment('Exp_1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r95Qrv2IlhXR",
        "outputId": "88a619b3-5574-41c8-e930-dd274df3eb0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/23 13:15:00 INFO mlflow.tracking.fluent: Experiment with name 'Exp_1' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='/content/mlruns/1', creation_time=1748006100220, experiment_id='1', last_update_time=1748006100220, lifecycle_stage='active', name='Exp_1', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Que 1**. Mlflow version?"
      ],
      "metadata": {
        "id": "AODTjOYy4FMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mlflow --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AClOz0zfl2Tj",
        "outputId": "98fbb167-e2ed-490b-fe1c-277a97192808"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mlflow, version 2.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data():\n",
        "\n",
        "    def dump_pickle(obj, filename: str):\n",
        "        with open(filename, \"wb\") as f_out:\n",
        "            return pickle.dump(obj, f_out)\n",
        "\n",
        "    def read_dataframe(filename: str):\n",
        "        df = pd.read_parquet(filename)\n",
        "\n",
        "        df['duration'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
        "        df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
        "        df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
        "\n",
        "        categorical = ['PULocationID', 'DOLocationID']\n",
        "        df[categorical] = df[categorical].astype(str)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def preprocess(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
        "\n",
        "        df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
        "        categorical = ['PU_DO']\n",
        "        numerical = ['trip_distance']\n",
        "        dicts = df[categorical + numerical].to_dict(orient='records')\n",
        "\n",
        "        if fit_dv: X = dv.fit_transform(dicts)\n",
        "        else: X = dv.transform(dicts)\n",
        "        return X, dv\n",
        "\n",
        "    def run_data_prep(raw_data_path='/content', dest_path='/content/Output', dataset: str = \"green\"):\n",
        "\n",
        "        df_train = read_dataframe(os.path.join(raw_data_path, f\"{dataset}_tripdata_2023-01.parquet\"))\n",
        "        df_val = read_dataframe(os.path.join(raw_data_path, f\"{dataset}_tripdata_2023-02.parquet\"))\n",
        "        df_test = read_dataframe(os.path.join(raw_data_path, f\"{dataset}_tripdata_2023-03.parquet\"))\n",
        "\n",
        "        target = 'duration'\n",
        "        y_train = df_train[target].values\n",
        "        y_val = df_val[target].values\n",
        "        y_test = df_test[target].values\n",
        "\n",
        "        dv = DictVectorizer()\n",
        "        X_train, dv = preprocess(df_train, dv, fit_dv=True)\n",
        "        X_val, _ = preprocess(df_val, dv, fit_dv=False)\n",
        "        X_test, _ = preprocess(df_test, dv, fit_dv=False)\n",
        "\n",
        "        os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "        dump_pickle(dv, os.path.join(dest_path, \"dv.pkl\"))\n",
        "        dump_pickle((X_train, y_train), os.path.join(dest_path, \"train.pkl\"))\n",
        "        dump_pickle((X_val, y_val), os.path.join(dest_path, \"val.pkl\"))\n",
        "        dump_pickle((X_test, y_test), os.path.join(dest_path, \"test.pkl\"))\n",
        "\n",
        "    run_data_prep()"
      ],
      "metadata": {
        "id": "2rNfxYkYvM9k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_data()"
      ],
      "metadata": {
        "id": "l_qiSBjuy1bU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Que 2**. Number of files that were saved in output folder?"
      ],
      "metadata": {
        "id": "LVv2RrUr4Lm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/Output | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEAqPN794UrX",
        "outputId": "b1780837-0fd8-4f42-d85a-df622f7f4148"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
      ],
      "metadata": {
        "id": "wRMa7fE955Ib"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "\n",
        "    def load_pickle(filename: str):\n",
        "        with open(filename, \"rb\") as f_in:\n",
        "            return pickle.load(f_in)\n",
        "\n",
        "    def run_train(data_path='/content/Output'):\n",
        "\n",
        "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
        "        X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
        "\n",
        "        mlflow.autolog()\n",
        "\n",
        "        rf = RandomForestRegressor(max_depth=10, random_state=0)\n",
        "        rf.fit(X_train, y_train)\n",
        "        y_pred = rf.predict(X_val)\n",
        "\n",
        "        rmse = root_mean_squared_error(y_val, y_pred)\n",
        "\n",
        "    run_train()"
      ],
      "metadata": {
        "id": "YSBDbvjMv01k"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW3cEFwyy5vG",
        "outputId": "66694c4d-4183-4172-df48-711f9fb7f467",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/23 13:16:22 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2025/05/23 13:16:25 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
            "2025/05/23 13:16:25 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2025/05/23 13:16:25 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2025/05/23 13:16:25 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '6e36864218b64273a3fd769044f643b1', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Que 3**. Value of min_sample_slit?"
      ],
      "metadata": {
        "id": "yF5tMd6I6j5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = client.search_runs(experiment_ids=[client.get_experiment_by_name('Exp_1').experiment_id])"
      ],
      "metadata": {
        "id": "GB_C0fUM6qbI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = run[0].data.params['min_samples_split']"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MlumY13K8DSC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'min_sample_split: {splits}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrYBB6mt92v7",
        "outputId": "0f49a1eb-0050-4e90-f26d-6dd06827f06d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_sample_split: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MLflow tracking URI with SQLite\n",
        "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
        "FOLDER = '/artifacts'\n",
        "\n",
        "# Start the MLflow server using subprocess\n",
        "subprocess.Popen([\"mlflow\", \"ui\", \"--backend-store-uri\", MLFLOW_TRACKING_URI, '--default-artifact-root', FOLDER, \"--port\", \"5000\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQE2JhHWAHC3",
        "outputId": "a33ed668-0647-446a-9502-43444270abbe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['mlflow', 'ui', '--backend-store-uri', 'sqli...>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Expose the MLflow UI on port 5000\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f' * ngrok tunnel \"{public_url}\" -> \"http://127.0.0.1:{port}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXz5QoTiA-rV",
        "outputId": "cd5d746d-7f01-4c3f-b9fa-843e5449e974"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://7b45-35-194-151-48.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hpo():\n",
        "\n",
        "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
        "    mlflow.set_experiment(\"random-forest-hyperopt\")\n",
        "\n",
        "    def load_pickle(filename: str):\n",
        "        with open(filename, \"rb\") as f_in:\n",
        "            return pickle.load(f_in)\n",
        "\n",
        "    def run_optimization(data_path='/content/Output', num_trials=15):\n",
        "\n",
        "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
        "        X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
        "\n",
        "        def objective(params):\n",
        "\n",
        "            with mlflow.start_run():\n",
        "\n",
        "                mlflow.log_params(params)\n",
        "\n",
        "                rf = RandomForestRegressor(**params)\n",
        "                rf.fit(X_train, y_train)\n",
        "                y_pred = rf.predict(X_val)\n",
        "                rmse = root_mean_squared_error(y_val, y_pred)\n",
        "\n",
        "                mlflow.log_metric('RMSE', rmse)\n",
        "\n",
        "                return {'loss': rmse, 'status': STATUS_OK}\n",
        "\n",
        "        search_space = {\n",
        "            'max_depth': scope.int(hp.quniform('max_depth', 1, 20, 1)),\n",
        "            'n_estimators': scope.int(hp.quniform('n_estimators', 10, 50, 1)),\n",
        "            'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
        "            'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 4, 1)),\n",
        "            'random_state': 42\n",
        "        }\n",
        "\n",
        "        rstate = np.random.default_rng(42)\n",
        "        fmin(\n",
        "            fn=objective,\n",
        "            space=search_space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=num_trials,\n",
        "            trials=Trials(),\n",
        "            rstate=rstate\n",
        "        )\n",
        "\n",
        "    run_optimization()"
      ],
      "metadata": {
        "id": "6_kBTNTI3FDy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hpo()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VptD3PHt3PZf",
        "outputId": "29cb4fec-fddd-459f-b937-714780ec240f",
        "collapsed": true
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/23 13:17:40 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-hyperopt' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🏃 View run capable-dolphin-712 at: http://127.0.0.1:5000/#/experiments/2/runs/0f2d91d499a74f9c9a2ac18b8f9522c2\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run wistful-dolphin-208 at: http://127.0.0.1:5000/#/experiments/2/runs/a7b4b590002848f4971ace482fcf9bc6\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run clumsy-gnu-0 at: http://127.0.0.1:5000/#/experiments/2/runs/732b73db6b7e40a18d5536e25f433938\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run peaceful-gnat-832 at: http://127.0.0.1:5000/#/experiments/2/runs/eb678ac06ef0468693db8cdf91fdf1c1\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run unruly-fish-721 at: http://127.0.0.1:5000/#/experiments/2/runs/2c2b8cbb45904f27be139595488ba0a9\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run persistent-fowl-168 at: http://127.0.0.1:5000/#/experiments/2/runs/f5e2da6ebc6b40f5bcfcbe70dc49e2cc\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run thoughtful-calf-372 at: http://127.0.0.1:5000/#/experiments/2/runs/37e500f75d5b4acb96b863fb3ed271a8\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run resilient-bee-361 at: http://127.0.0.1:5000/#/experiments/2/runs/fd5b397aa4064939968d4ec212b56638\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run suave-colt-67 at: http://127.0.0.1:5000/#/experiments/2/runs/376e360c9ece4f82a46194844ca85a26\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run nervous-skink-228 at: http://127.0.0.1:5000/#/experiments/2/runs/755ed3b191434fe79957d50908a54828\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run amazing-eel-237 at: http://127.0.0.1:5000/#/experiments/2/runs/03c8866e37394835bc547690e99957b2\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run burly-swan-165 at: http://127.0.0.1:5000/#/experiments/2/runs/39f8955365aa4ee3a5df2ed5129c8147\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run rumbling-skink-192 at: http://127.0.0.1:5000/#/experiments/2/runs/7b97fac15b77459687a046207338712e\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run nebulous-moose-518 at: http://127.0.0.1:5000/#/experiments/2/runs/c9ca928e85354ff29af1a458b10bdfe2\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "🏃 View run bittersweet-roo-762 at: http://127.0.0.1:5000/#/experiments/2/runs/000827676d584bcda69502b2278e1946\n",
            "\n",
            "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
            "\n",
            "100%|██████████| 15/15 [04:22<00:00, 17.51s/trial, best loss: 5.335419588556921]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Que 5.** Minimum validation RMSE value?"
      ],
      "metadata": {
        "id": "ikzuoRCjKQ49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = client.search_runs(experiment_ids=[client.get_experiment_by_name('random-forest-hyperopt').experiment_id])\n",
        "valid_rmse = sorted([run.data.metrics['RMSE'] for run in runs])\n",
        "print(f'minimum_validation_rmse: {valid_rmse[0]}')"
      ],
      "metadata": {
        "id": "yYArI6h6HiYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8520bb-797a-4725-b1d6-1ba492a4f033"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum_validation_rmse: 5.335419588556921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def register_model():\n",
        "    HPO_EXPERIMENT_NAME = \"random-forest-hyperopt\"\n",
        "    EXPERIMENT_NAME = \"random-forest-best-models\"\n",
        "    RF_PARAMS = ['max_depth', 'n_estimators', 'min_samples_split', 'min_samples_leaf', 'random_state']\n",
        "\n",
        "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "    mlflow.sklearn.autolog()\n",
        "\n",
        "\n",
        "    def load_pickle(filename):\n",
        "        with open(filename, \"rb\") as f_in:\n",
        "            return pickle.load(f_in)\n",
        "\n",
        "\n",
        "    def train_and_log_model(data_path, params):\n",
        "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
        "        X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
        "        X_test, y_test = load_pickle(os.path.join(data_path, \"test.pkl\"))\n",
        "\n",
        "        with mlflow.start_run():\n",
        "            new_params = {}\n",
        "            for param in RF_PARAMS:\n",
        "                new_params[param] = int(params[param])\n",
        "\n",
        "            rf = RandomForestRegressor(**new_params)\n",
        "            rf.fit(X_train, y_train)\n",
        "\n",
        "            # Evaluate model on the validation and test sets\n",
        "            val_rmse = root_mean_squared_error(y_val, rf.predict(X_val))\n",
        "            mlflow.log_metric(\"val_rmse\", val_rmse)\n",
        "            test_rmse = root_mean_squared_error(y_test, rf.predict(X_test))\n",
        "            mlflow.log_metric(\"test_rmse\", test_rmse)\n",
        "\n",
        "    def run_register_model(data_path='/content/Output', top_n=5):\n",
        "\n",
        "        client = MlflowClient()\n",
        "\n",
        "        # Retrieve the top_n model runs and log the models\n",
        "        experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
        "        runs = client.search_runs(\n",
        "            experiment_ids=experiment.experiment_id,\n",
        "            run_view_type=ViewType.ACTIVE_ONLY,\n",
        "            max_results=top_n,\n",
        "            order_by=[\"metrics.rmse ASC\"]\n",
        "        )\n",
        "        for run in runs:\n",
        "            train_and_log_model(data_path=data_path, params=run.data.params)\n",
        "\n",
        "        # Select the model with the lowest test RMSE\n",
        "        experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
        "        best_run = client.search_runs(\n",
        "            experiment_ids=experiment.experiment_id,\n",
        "            order_by=['metrics.test_rmse ASC']\n",
        "        )[0]\n",
        "\n",
        "        # Register the best model\n",
        "        mlflow.register_model(\n",
        "            model_uri=f'runs:/{best_run.info.run_id}/model',\n",
        "            name='random-forest-model-registry'\n",
        "        )\n",
        "\n",
        "    run_register_model()\n"
      ],
      "metadata": {
        "id": "9NlDnziHKHVF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "register_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iJXIXkOWQC7",
        "outputId": "1fd3fdf8-3b29-4af9-8b82-9dc9ad81fd4a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/05/23 13:22:25 INFO mlflow.tracking.fluent: Experiment with name 'random-forest-best-models' does not exist. Creating a new experiment.\n",
            "Successfully registered model 'random-forest-model-registry'.\n",
            "Created version '1' of model 'random-forest-model-registry'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Que 6.** Test_rmse for regitered model?\n"
      ],
      "metadata": {
        "id": "7v_b9G_CZ1iG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = client.get_registered_model('random-forest-model-registry')\n",
        "run_id = model.latest_versions[0].run_id\n",
        "test_rmse = client.get_run(run_id).data.metrics['test_rmse']\n",
        "print(f'test_rmse: {test_rmse}')"
      ],
      "metadata": {
        "id": "qK7CJ4EpWSC9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56de9096-8729-45f5-a85c-6245bfb78d33"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_rmse: 5.567408012462019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qKsazvqfZyf_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMey9CdeIr6LN3mHEpNCnVl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}